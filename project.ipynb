{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy pandas scikit-learn seaborn matplotlib xgboost deap --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparative Study Between Ensemble Learning and Evolutionary Learning to solve the Higgs Bozon Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import xgboost as xgb\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(818238, 35)\n",
      "EventId                          int64\n",
      "DER_mass_MMC                   float64\n",
      "DER_mass_transverse_met_lep    float64\n",
      "DER_mass_vis                   float64\n",
      "DER_pt_h                       float64\n",
      "DER_deltaeta_jet_jet           float64\n",
      "DER_mass_jet_jet               float64\n",
      "DER_prodeta_jet_jet            float64\n",
      "DER_deltar_tau_lep             float64\n",
      "DER_pt_tot                     float64\n",
      "DER_sum_pt                     float64\n",
      "DER_pt_ratio_lep_tau           float64\n",
      "DER_met_phi_centrality         float64\n",
      "DER_lep_eta_centrality         float64\n",
      "PRI_tau_pt                     float64\n",
      "PRI_tau_eta                    float64\n",
      "PRI_tau_phi                    float64\n",
      "PRI_lep_pt                     float64\n",
      "PRI_lep_eta                    float64\n",
      "PRI_lep_phi                    float64\n",
      "PRI_met                        float64\n",
      "PRI_met_phi                    float64\n",
      "PRI_met_sumet                  float64\n",
      "PRI_jet_num                      int64\n",
      "PRI_jet_leading_pt             float64\n",
      "PRI_jet_leading_eta            float64\n",
      "PRI_jet_leading_phi            float64\n",
      "PRI_jet_subleading_pt          float64\n",
      "PRI_jet_subleading_eta         float64\n",
      "PRI_jet_subleading_phi         float64\n",
      "PRI_jet_all_pt                 float64\n",
      "Weight                         float64\n",
      "Label                           object\n",
      "KaggleSet                       object\n",
      "KaggleWeight                   float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "dataFilename = './atlas-higgs.csv'\n",
    "data = pd.read_csv(dataFilename)\n",
    "\n",
    "print(data.shape)\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventId</th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>DER_pt_tot</th>\n",
       "      <th>...</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Label</th>\n",
       "      <th>KaggleSet</th>\n",
       "      <th>KaggleWeight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>138.470</td>\n",
       "      <td>51.655</td>\n",
       "      <td>97.827</td>\n",
       "      <td>27.980</td>\n",
       "      <td>0.91</td>\n",
       "      <td>124.711</td>\n",
       "      <td>2.666</td>\n",
       "      <td>3.064</td>\n",
       "      <td>41.928</td>\n",
       "      <td>...</td>\n",
       "      <td>2.150</td>\n",
       "      <td>0.444</td>\n",
       "      <td>46.062</td>\n",
       "      <td>1.24</td>\n",
       "      <td>-2.475</td>\n",
       "      <td>113.497</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "      <td>0.002653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>160.937</td>\n",
       "      <td>68.768</td>\n",
       "      <td>103.235</td>\n",
       "      <td>48.146</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.473</td>\n",
       "      <td>2.078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725</td>\n",
       "      <td>1.158</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>46.226</td>\n",
       "      <td>0.681042</td>\n",
       "      <td>b</td>\n",
       "      <td>t</td>\n",
       "      <td>2.233584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>162.172</td>\n",
       "      <td>125.953</td>\n",
       "      <td>35.635</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.148</td>\n",
       "      <td>9.336</td>\n",
       "      <td>...</td>\n",
       "      <td>2.053</td>\n",
       "      <td>-2.028</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>44.251</td>\n",
       "      <td>0.715742</td>\n",
       "      <td>b</td>\n",
       "      <td>t</td>\n",
       "      <td>2.347389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003</td>\n",
       "      <td>143.905</td>\n",
       "      <td>81.417</td>\n",
       "      <td>80.943</td>\n",
       "      <td>0.414</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.310</td>\n",
       "      <td>0.414</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1.660654</td>\n",
       "      <td>b</td>\n",
       "      <td>t</td>\n",
       "      <td>5.446378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100004</td>\n",
       "      <td>175.864</td>\n",
       "      <td>16.915</td>\n",
       "      <td>134.805</td>\n",
       "      <td>16.405</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.891</td>\n",
       "      <td>16.405</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.904263</td>\n",
       "      <td>b</td>\n",
       "      <td>t</td>\n",
       "      <td>6.245333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EventId  DER_mass_MMC  DER_mass_transverse_met_lep  DER_mass_vis  DER_pt_h  \\\n",
       "0   100000       138.470                       51.655        97.827    27.980   \n",
       "1   100001       160.937                       68.768       103.235    48.146   \n",
       "2   100002      -999.000                      162.172       125.953    35.635   \n",
       "3   100003       143.905                       81.417        80.943     0.414   \n",
       "4   100004       175.864                       16.915       134.805    16.405   \n",
       "\n",
       "   DER_deltaeta_jet_jet  DER_mass_jet_jet  DER_prodeta_jet_jet  \\\n",
       "0                  0.91           124.711                2.666   \n",
       "1               -999.00          -999.000             -999.000   \n",
       "2               -999.00          -999.000             -999.000   \n",
       "3               -999.00          -999.000             -999.000   \n",
       "4               -999.00          -999.000             -999.000   \n",
       "\n",
       "   DER_deltar_tau_lep  DER_pt_tot  ...  PRI_jet_leading_eta  \\\n",
       "0               3.064      41.928  ...                2.150   \n",
       "1               3.473       2.078  ...                0.725   \n",
       "2               3.148       9.336  ...                2.053   \n",
       "3               3.310       0.414  ...             -999.000   \n",
       "4               3.891      16.405  ...             -999.000   \n",
       "\n",
       "   PRI_jet_leading_phi  PRI_jet_subleading_pt  PRI_jet_subleading_eta  \\\n",
       "0                0.444                 46.062                    1.24   \n",
       "1                1.158               -999.000                 -999.00   \n",
       "2               -2.028               -999.000                 -999.00   \n",
       "3             -999.000               -999.000                 -999.00   \n",
       "4             -999.000               -999.000                 -999.00   \n",
       "\n",
       "   PRI_jet_subleading_phi  PRI_jet_all_pt    Weight  Label  KaggleSet  \\\n",
       "0                  -2.475         113.497  0.000814      s          t   \n",
       "1                -999.000          46.226  0.681042      b          t   \n",
       "2                -999.000          44.251  0.715742      b          t   \n",
       "3                -999.000          -0.000  1.660654      b          t   \n",
       "4                -999.000           0.000  1.904263      b          t   \n",
       "\n",
       "   KaggleWeight  \n",
       "0      0.002653  \n",
       "1      2.233584  \n",
       "2      2.347389  \n",
       "3      5.446378  \n",
       "4      6.245333  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>DER_pt_tot</th>\n",
       "      <th>DER_sum_pt</th>\n",
       "      <th>...</th>\n",
       "      <th>PRI_met_sumet</th>\n",
       "      <th>PRI_jet_num</th>\n",
       "      <th>PRI_jet_leading_pt</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138.470</td>\n",
       "      <td>51.655</td>\n",
       "      <td>97.827</td>\n",
       "      <td>27.980</td>\n",
       "      <td>0.910</td>\n",
       "      <td>124.711</td>\n",
       "      <td>2.666</td>\n",
       "      <td>3.064</td>\n",
       "      <td>41.928</td>\n",
       "      <td>197.760</td>\n",
       "      <td>...</td>\n",
       "      <td>258.733</td>\n",
       "      <td>2</td>\n",
       "      <td>67.435</td>\n",
       "      <td>2.150</td>\n",
       "      <td>0.444</td>\n",
       "      <td>46.062</td>\n",
       "      <td>1.240</td>\n",
       "      <td>-2.475</td>\n",
       "      <td>113.497</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>160.937</td>\n",
       "      <td>68.768</td>\n",
       "      <td>103.235</td>\n",
       "      <td>48.146</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.473</td>\n",
       "      <td>2.078</td>\n",
       "      <td>125.157</td>\n",
       "      <td>...</td>\n",
       "      <td>164.546</td>\n",
       "      <td>1</td>\n",
       "      <td>46.226</td>\n",
       "      <td>0.725</td>\n",
       "      <td>1.158</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>46.226</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-999.000</td>\n",
       "      <td>162.172</td>\n",
       "      <td>125.953</td>\n",
       "      <td>35.635</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.148</td>\n",
       "      <td>9.336</td>\n",
       "      <td>197.814</td>\n",
       "      <td>...</td>\n",
       "      <td>260.414</td>\n",
       "      <td>1</td>\n",
       "      <td>44.251</td>\n",
       "      <td>2.053</td>\n",
       "      <td>-2.028</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>44.251</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>143.905</td>\n",
       "      <td>81.417</td>\n",
       "      <td>80.943</td>\n",
       "      <td>0.414</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.310</td>\n",
       "      <td>0.414</td>\n",
       "      <td>75.968</td>\n",
       "      <td>...</td>\n",
       "      <td>86.062</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175.864</td>\n",
       "      <td>16.915</td>\n",
       "      <td>134.805</td>\n",
       "      <td>16.405</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.891</td>\n",
       "      <td>16.405</td>\n",
       "      <td>57.983</td>\n",
       "      <td>...</td>\n",
       "      <td>53.131</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818233</th>\n",
       "      <td>105.668</td>\n",
       "      <td>46.443</td>\n",
       "      <td>60.048</td>\n",
       "      <td>156.191</td>\n",
       "      <td>0.403</td>\n",
       "      <td>47.746</td>\n",
       "      <td>0.936</td>\n",
       "      <td>1.279</td>\n",
       "      <td>6.133</td>\n",
       "      <td>256.853</td>\n",
       "      <td>...</td>\n",
       "      <td>303.668</td>\n",
       "      <td>2</td>\n",
       "      <td>112.264</td>\n",
       "      <td>1.190</td>\n",
       "      <td>-0.766</td>\n",
       "      <td>41.791</td>\n",
       "      <td>0.787</td>\n",
       "      <td>-1.090</td>\n",
       "      <td>154.056</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818234</th>\n",
       "      <td>99.294</td>\n",
       "      <td>30.097</td>\n",
       "      <td>62.713</td>\n",
       "      <td>65.861</td>\n",
       "      <td>3.312</td>\n",
       "      <td>471.319</td>\n",
       "      <td>-2.611</td>\n",
       "      <td>2.294</td>\n",
       "      <td>2.889</td>\n",
       "      <td>248.582</td>\n",
       "      <td>...</td>\n",
       "      <td>266.919</td>\n",
       "      <td>2</td>\n",
       "      <td>108.698</td>\n",
       "      <td>1.293</td>\n",
       "      <td>-0.868</td>\n",
       "      <td>70.158</td>\n",
       "      <td>-2.018</td>\n",
       "      <td>2.893</td>\n",
       "      <td>178.856</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818235</th>\n",
       "      <td>108.497</td>\n",
       "      <td>9.837</td>\n",
       "      <td>65.149</td>\n",
       "      <td>18.006</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.742</td>\n",
       "      <td>18.006</td>\n",
       "      <td>68.097</td>\n",
       "      <td>...</td>\n",
       "      <td>188.648</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818236</th>\n",
       "      <td>96.711</td>\n",
       "      <td>20.006</td>\n",
       "      <td>66.942</td>\n",
       "      <td>29.761</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.479</td>\n",
       "      <td>2.739</td>\n",
       "      <td>101.676</td>\n",
       "      <td>...</td>\n",
       "      <td>212.565</td>\n",
       "      <td>1</td>\n",
       "      <td>30.863</td>\n",
       "      <td>1.460</td>\n",
       "      <td>2.637</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>30.863</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818237</th>\n",
       "      <td>92.373</td>\n",
       "      <td>80.109</td>\n",
       "      <td>77.619</td>\n",
       "      <td>3.984</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.486</td>\n",
       "      <td>3.984</td>\n",
       "      <td>77.348</td>\n",
       "      <td>...</td>\n",
       "      <td>97.379</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>818238 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DER_mass_MMC  DER_mass_transverse_met_lep  DER_mass_vis  DER_pt_h  \\\n",
       "0            138.470                       51.655        97.827    27.980   \n",
       "1            160.937                       68.768       103.235    48.146   \n",
       "2           -999.000                      162.172       125.953    35.635   \n",
       "3            143.905                       81.417        80.943     0.414   \n",
       "4            175.864                       16.915       134.805    16.405   \n",
       "...              ...                          ...           ...       ...   \n",
       "818233       105.668                       46.443        60.048   156.191   \n",
       "818234        99.294                       30.097        62.713    65.861   \n",
       "818235       108.497                        9.837        65.149    18.006   \n",
       "818236        96.711                       20.006        66.942    29.761   \n",
       "818237        92.373                       80.109        77.619     3.984   \n",
       "\n",
       "        DER_deltaeta_jet_jet  DER_mass_jet_jet  DER_prodeta_jet_jet  \\\n",
       "0                      0.910           124.711                2.666   \n",
       "1                   -999.000          -999.000             -999.000   \n",
       "2                   -999.000          -999.000             -999.000   \n",
       "3                   -999.000          -999.000             -999.000   \n",
       "4                   -999.000          -999.000             -999.000   \n",
       "...                      ...               ...                  ...   \n",
       "818233                 0.403            47.746                0.936   \n",
       "818234                 3.312           471.319               -2.611   \n",
       "818235              -999.000          -999.000             -999.000   \n",
       "818236              -999.000          -999.000             -999.000   \n",
       "818237              -999.000          -999.000             -999.000   \n",
       "\n",
       "        DER_deltar_tau_lep  DER_pt_tot  DER_sum_pt  ...  PRI_met_sumet  \\\n",
       "0                    3.064      41.928     197.760  ...        258.733   \n",
       "1                    3.473       2.078     125.157  ...        164.546   \n",
       "2                    3.148       9.336     197.814  ...        260.414   \n",
       "3                    3.310       0.414      75.968  ...         86.062   \n",
       "4                    3.891      16.405      57.983  ...         53.131   \n",
       "...                    ...         ...         ...  ...            ...   \n",
       "818233               1.279       6.133     256.853  ...        303.668   \n",
       "818234               2.294       2.889     248.582  ...        266.919   \n",
       "818235               2.742      18.006      68.097  ...        188.648   \n",
       "818236               2.479       2.739     101.676  ...        212.565   \n",
       "818237               2.486       3.984      77.348  ...         97.379   \n",
       "\n",
       "        PRI_jet_num  PRI_jet_leading_pt  PRI_jet_leading_eta  \\\n",
       "0                 2              67.435                2.150   \n",
       "1                 1              46.226                0.725   \n",
       "2                 1              44.251                2.053   \n",
       "3                 0            -999.000             -999.000   \n",
       "4                 0            -999.000             -999.000   \n",
       "...             ...                 ...                  ...   \n",
       "818233            2             112.264                1.190   \n",
       "818234            2             108.698                1.293   \n",
       "818235            0            -999.000             -999.000   \n",
       "818236            1              30.863                1.460   \n",
       "818237            0            -999.000             -999.000   \n",
       "\n",
       "        PRI_jet_leading_phi  PRI_jet_subleading_pt  PRI_jet_subleading_eta  \\\n",
       "0                     0.444                 46.062                   1.240   \n",
       "1                     1.158               -999.000                -999.000   \n",
       "2                    -2.028               -999.000                -999.000   \n",
       "3                  -999.000               -999.000                -999.000   \n",
       "4                  -999.000               -999.000                -999.000   \n",
       "...                     ...                    ...                     ...   \n",
       "818233               -0.766                 41.791                   0.787   \n",
       "818234               -0.868                 70.158                  -2.018   \n",
       "818235             -999.000               -999.000                -999.000   \n",
       "818236                2.637               -999.000                -999.000   \n",
       "818237             -999.000               -999.000                -999.000   \n",
       "\n",
       "        PRI_jet_subleading_phi  PRI_jet_all_pt  Label  \n",
       "0                       -2.475         113.497      1  \n",
       "1                     -999.000          46.226      0  \n",
       "2                     -999.000          44.251      0  \n",
       "3                     -999.000          -0.000      0  \n",
       "4                     -999.000           0.000      0  \n",
       "...                        ...             ...    ...  \n",
       "818233                  -1.090         154.056      1  \n",
       "818234                   2.893         178.856      1  \n",
       "818235                -999.000          -0.000      0  \n",
       "818236                -999.000          30.863      0  \n",
       "818237                -999.000          -0.000      0  \n",
       "\n",
       "[818238 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del(data['EventId'])\n",
    "del(data['Weight'])\n",
    "del(data['KaggleSet'])\n",
    "del(data['KaggleWeight'])\n",
    "\n",
    "Encoder = LabelEncoder()\n",
    "\n",
    "data['Label'] = Encoder.fit_transform(data['Label'])\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling missing values\n",
    "\n",
    "Missing data in this file are designated -999."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>DER_pt_tot</th>\n",
       "      <th>DER_sum_pt</th>\n",
       "      <th>...</th>\n",
       "      <th>PRI_met_sumet</th>\n",
       "      <th>PRI_jet_num</th>\n",
       "      <th>PRI_jet_leading_pt</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138.470000</td>\n",
       "      <td>51.655</td>\n",
       "      <td>97.827</td>\n",
       "      <td>27.980</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>124.71100</td>\n",
       "      <td>2.66600</td>\n",
       "      <td>3.064</td>\n",
       "      <td>41.928</td>\n",
       "      <td>197.760</td>\n",
       "      <td>...</td>\n",
       "      <td>258.733</td>\n",
       "      <td>2.0</td>\n",
       "      <td>67.435000</td>\n",
       "      <td>2.150000</td>\n",
       "      <td>0.444000</td>\n",
       "      <td>46.062000</td>\n",
       "      <td>1.240000</td>\n",
       "      <td>-2.47500</td>\n",
       "      <td>113.497</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>160.937000</td>\n",
       "      <td>68.768</td>\n",
       "      <td>103.235</td>\n",
       "      <td>48.146</td>\n",
       "      <td>2.404626</td>\n",
       "      <td>372.18105</td>\n",
       "      <td>-0.82874</td>\n",
       "      <td>3.473</td>\n",
       "      <td>2.078</td>\n",
       "      <td>125.157</td>\n",
       "      <td>...</td>\n",
       "      <td>164.546</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.226000</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>1.158000</td>\n",
       "      <td>57.810286</td>\n",
       "      <td>-0.006669</td>\n",
       "      <td>-0.01047</td>\n",
       "      <td>46.226</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121.867697</td>\n",
       "      <td>162.172</td>\n",
       "      <td>125.953</td>\n",
       "      <td>35.635</td>\n",
       "      <td>2.404626</td>\n",
       "      <td>372.18105</td>\n",
       "      <td>-0.82874</td>\n",
       "      <td>3.148</td>\n",
       "      <td>9.336</td>\n",
       "      <td>197.814</td>\n",
       "      <td>...</td>\n",
       "      <td>260.414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.251000</td>\n",
       "      <td>2.053000</td>\n",
       "      <td>-2.028000</td>\n",
       "      <td>57.810286</td>\n",
       "      <td>-0.006669</td>\n",
       "      <td>-0.01047</td>\n",
       "      <td>44.251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>143.905000</td>\n",
       "      <td>81.417</td>\n",
       "      <td>80.943</td>\n",
       "      <td>0.414</td>\n",
       "      <td>2.404626</td>\n",
       "      <td>372.18105</td>\n",
       "      <td>-0.82874</td>\n",
       "      <td>3.310</td>\n",
       "      <td>0.414</td>\n",
       "      <td>75.968</td>\n",
       "      <td>...</td>\n",
       "      <td>86.062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.904285</td>\n",
       "      <td>-0.001248</td>\n",
       "      <td>-0.018856</td>\n",
       "      <td>57.810286</td>\n",
       "      <td>-0.006669</td>\n",
       "      <td>-0.01047</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175.864000</td>\n",
       "      <td>16.915</td>\n",
       "      <td>134.805</td>\n",
       "      <td>16.405</td>\n",
       "      <td>2.404626</td>\n",
       "      <td>372.18105</td>\n",
       "      <td>-0.82874</td>\n",
       "      <td>3.891</td>\n",
       "      <td>16.405</td>\n",
       "      <td>57.983</td>\n",
       "      <td>...</td>\n",
       "      <td>53.131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.904285</td>\n",
       "      <td>-0.001248</td>\n",
       "      <td>-0.018856</td>\n",
       "      <td>57.810286</td>\n",
       "      <td>-0.006669</td>\n",
       "      <td>-0.01047</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818233</th>\n",
       "      <td>105.668000</td>\n",
       "      <td>46.443</td>\n",
       "      <td>60.048</td>\n",
       "      <td>156.191</td>\n",
       "      <td>0.403000</td>\n",
       "      <td>47.74600</td>\n",
       "      <td>0.93600</td>\n",
       "      <td>1.279</td>\n",
       "      <td>6.133</td>\n",
       "      <td>256.853</td>\n",
       "      <td>...</td>\n",
       "      <td>303.668</td>\n",
       "      <td>2.0</td>\n",
       "      <td>112.264000</td>\n",
       "      <td>1.190000</td>\n",
       "      <td>-0.766000</td>\n",
       "      <td>41.791000</td>\n",
       "      <td>0.787000</td>\n",
       "      <td>-1.09000</td>\n",
       "      <td>154.056</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818234</th>\n",
       "      <td>99.294000</td>\n",
       "      <td>30.097</td>\n",
       "      <td>62.713</td>\n",
       "      <td>65.861</td>\n",
       "      <td>3.312000</td>\n",
       "      <td>471.31900</td>\n",
       "      <td>-2.61100</td>\n",
       "      <td>2.294</td>\n",
       "      <td>2.889</td>\n",
       "      <td>248.582</td>\n",
       "      <td>...</td>\n",
       "      <td>266.919</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.698000</td>\n",
       "      <td>1.293000</td>\n",
       "      <td>-0.868000</td>\n",
       "      <td>70.158000</td>\n",
       "      <td>-2.018000</td>\n",
       "      <td>2.89300</td>\n",
       "      <td>178.856</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818235</th>\n",
       "      <td>108.497000</td>\n",
       "      <td>9.837</td>\n",
       "      <td>65.149</td>\n",
       "      <td>18.006</td>\n",
       "      <td>2.404626</td>\n",
       "      <td>372.18105</td>\n",
       "      <td>-0.82874</td>\n",
       "      <td>2.742</td>\n",
       "      <td>18.006</td>\n",
       "      <td>68.097</td>\n",
       "      <td>...</td>\n",
       "      <td>188.648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.904285</td>\n",
       "      <td>-0.001248</td>\n",
       "      <td>-0.018856</td>\n",
       "      <td>57.810286</td>\n",
       "      <td>-0.006669</td>\n",
       "      <td>-0.01047</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818236</th>\n",
       "      <td>96.711000</td>\n",
       "      <td>20.006</td>\n",
       "      <td>66.942</td>\n",
       "      <td>29.761</td>\n",
       "      <td>2.404626</td>\n",
       "      <td>372.18105</td>\n",
       "      <td>-0.82874</td>\n",
       "      <td>2.479</td>\n",
       "      <td>2.739</td>\n",
       "      <td>101.676</td>\n",
       "      <td>...</td>\n",
       "      <td>212.565</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.863000</td>\n",
       "      <td>1.460000</td>\n",
       "      <td>2.637000</td>\n",
       "      <td>57.810286</td>\n",
       "      <td>-0.006669</td>\n",
       "      <td>-0.01047</td>\n",
       "      <td>30.863</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818237</th>\n",
       "      <td>92.373000</td>\n",
       "      <td>80.109</td>\n",
       "      <td>77.619</td>\n",
       "      <td>3.984</td>\n",
       "      <td>2.404626</td>\n",
       "      <td>372.18105</td>\n",
       "      <td>-0.82874</td>\n",
       "      <td>2.486</td>\n",
       "      <td>3.984</td>\n",
       "      <td>77.348</td>\n",
       "      <td>...</td>\n",
       "      <td>97.379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.904285</td>\n",
       "      <td>-0.001248</td>\n",
       "      <td>-0.018856</td>\n",
       "      <td>57.810286</td>\n",
       "      <td>-0.006669</td>\n",
       "      <td>-0.01047</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>818238 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DER_mass_MMC  DER_mass_transverse_met_lep  DER_mass_vis  DER_pt_h  \\\n",
       "0         138.470000                       51.655        97.827    27.980   \n",
       "1         160.937000                       68.768       103.235    48.146   \n",
       "2         121.867697                      162.172       125.953    35.635   \n",
       "3         143.905000                       81.417        80.943     0.414   \n",
       "4         175.864000                       16.915       134.805    16.405   \n",
       "...              ...                          ...           ...       ...   \n",
       "818233    105.668000                       46.443        60.048   156.191   \n",
       "818234     99.294000                       30.097        62.713    65.861   \n",
       "818235    108.497000                        9.837        65.149    18.006   \n",
       "818236     96.711000                       20.006        66.942    29.761   \n",
       "818237     92.373000                       80.109        77.619     3.984   \n",
       "\n",
       "        DER_deltaeta_jet_jet  DER_mass_jet_jet  DER_prodeta_jet_jet  \\\n",
       "0                   0.910000         124.71100              2.66600   \n",
       "1                   2.404626         372.18105             -0.82874   \n",
       "2                   2.404626         372.18105             -0.82874   \n",
       "3                   2.404626         372.18105             -0.82874   \n",
       "4                   2.404626         372.18105             -0.82874   \n",
       "...                      ...               ...                  ...   \n",
       "818233              0.403000          47.74600              0.93600   \n",
       "818234              3.312000         471.31900             -2.61100   \n",
       "818235              2.404626         372.18105             -0.82874   \n",
       "818236              2.404626         372.18105             -0.82874   \n",
       "818237              2.404626         372.18105             -0.82874   \n",
       "\n",
       "        DER_deltar_tau_lep  DER_pt_tot  DER_sum_pt  ...  PRI_met_sumet  \\\n",
       "0                    3.064      41.928     197.760  ...        258.733   \n",
       "1                    3.473       2.078     125.157  ...        164.546   \n",
       "2                    3.148       9.336     197.814  ...        260.414   \n",
       "3                    3.310       0.414      75.968  ...         86.062   \n",
       "4                    3.891      16.405      57.983  ...         53.131   \n",
       "...                    ...         ...         ...  ...            ...   \n",
       "818233               1.279       6.133     256.853  ...        303.668   \n",
       "818234               2.294       2.889     248.582  ...        266.919   \n",
       "818235               2.742      18.006      68.097  ...        188.648   \n",
       "818236               2.479       2.739     101.676  ...        212.565   \n",
       "818237               2.486       3.984      77.348  ...         97.379   \n",
       "\n",
       "        PRI_jet_num  PRI_jet_leading_pt  PRI_jet_leading_eta  \\\n",
       "0               2.0           67.435000             2.150000   \n",
       "1               1.0           46.226000             0.725000   \n",
       "2               1.0           44.251000             2.053000   \n",
       "3               0.0           84.904285            -0.001248   \n",
       "4               0.0           84.904285            -0.001248   \n",
       "...             ...                 ...                  ...   \n",
       "818233          2.0          112.264000             1.190000   \n",
       "818234          2.0          108.698000             1.293000   \n",
       "818235          0.0           84.904285            -0.001248   \n",
       "818236          1.0           30.863000             1.460000   \n",
       "818237          0.0           84.904285            -0.001248   \n",
       "\n",
       "        PRI_jet_leading_phi  PRI_jet_subleading_pt  PRI_jet_subleading_eta  \\\n",
       "0                  0.444000              46.062000                1.240000   \n",
       "1                  1.158000              57.810286               -0.006669   \n",
       "2                 -2.028000              57.810286               -0.006669   \n",
       "3                 -0.018856              57.810286               -0.006669   \n",
       "4                 -0.018856              57.810286               -0.006669   \n",
       "...                     ...                    ...                     ...   \n",
       "818233            -0.766000              41.791000                0.787000   \n",
       "818234            -0.868000              70.158000               -2.018000   \n",
       "818235            -0.018856              57.810286               -0.006669   \n",
       "818236             2.637000              57.810286               -0.006669   \n",
       "818237            -0.018856              57.810286               -0.006669   \n",
       "\n",
       "        PRI_jet_subleading_phi  PRI_jet_all_pt  Label  \n",
       "0                     -2.47500         113.497    1.0  \n",
       "1                     -0.01047          46.226    0.0  \n",
       "2                     -0.01047          44.251    0.0  \n",
       "3                     -0.01047          -0.000    0.0  \n",
       "4                     -0.01047           0.000    0.0  \n",
       "...                        ...             ...    ...  \n",
       "818233                -1.09000         154.056    1.0  \n",
       "818234                 2.89300         178.856    1.0  \n",
       "818235                -0.01047          -0.000    0.0  \n",
       "818236                -0.01047          30.863    0.0  \n",
       "818237                -0.01047          -0.000    0.0  \n",
       "\n",
       "[818238 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = SimpleImputer(missing_values=-999, strategy='mean')\n",
    "\n",
    "columns = data.columns\n",
    "numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "data[numeric_cols] = imputer.fit_transform(data[numeric_cols])\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>DER_pt_tot</th>\n",
       "      <th>DER_sum_pt</th>\n",
       "      <th>...</th>\n",
       "      <th>PRI_met_sumet</th>\n",
       "      <th>PRI_jet_num</th>\n",
       "      <th>PRI_jet_leading_pt</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.066707</td>\n",
       "      <td>0.053326</td>\n",
       "      <td>0.068128</td>\n",
       "      <td>0.009869</td>\n",
       "      <td>0.104310</td>\n",
       "      <td>0.022395</td>\n",
       "      <td>0.591293</td>\n",
       "      <td>0.515244</td>\n",
       "      <td>0.014789</td>\n",
       "      <td>0.074595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112586</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.033028</td>\n",
       "      <td>0.738889</td>\n",
       "      <td>0.570656</td>\n",
       "      <td>0.020388</td>\n",
       "      <td>0.637778</td>\n",
       "      <td>0.106143</td>\n",
       "      <td>0.061014</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.078287</td>\n",
       "      <td>0.070992</td>\n",
       "      <td>0.072155</td>\n",
       "      <td>0.016983</td>\n",
       "      <td>0.275633</td>\n",
       "      <td>0.072274</td>\n",
       "      <td>0.495970</td>\n",
       "      <td>0.589031</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.038884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069314</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.014316</td>\n",
       "      <td>0.580556</td>\n",
       "      <td>0.684278</td>\n",
       "      <td>0.035301</td>\n",
       "      <td>0.499259</td>\n",
       "      <td>0.498334</td>\n",
       "      <td>0.024850</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.058150</td>\n",
       "      <td>0.167417</td>\n",
       "      <td>0.089071</td>\n",
       "      <td>0.012570</td>\n",
       "      <td>0.275633</td>\n",
       "      <td>0.072274</td>\n",
       "      <td>0.495970</td>\n",
       "      <td>0.530399</td>\n",
       "      <td>0.003293</td>\n",
       "      <td>0.074622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113359</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.012573</td>\n",
       "      <td>0.728111</td>\n",
       "      <td>0.177276</td>\n",
       "      <td>0.035301</td>\n",
       "      <td>0.499259</td>\n",
       "      <td>0.498334</td>\n",
       "      <td>0.023789</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.069508</td>\n",
       "      <td>0.084050</td>\n",
       "      <td>0.055557</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.275633</td>\n",
       "      <td>0.072274</td>\n",
       "      <td>0.495970</td>\n",
       "      <td>0.559625</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.014690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048440</td>\n",
       "      <td>0.499861</td>\n",
       "      <td>0.496999</td>\n",
       "      <td>0.035301</td>\n",
       "      <td>0.499259</td>\n",
       "      <td>0.498334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.085980</td>\n",
       "      <td>0.017462</td>\n",
       "      <td>0.095662</td>\n",
       "      <td>0.005787</td>\n",
       "      <td>0.275633</td>\n",
       "      <td>0.072274</td>\n",
       "      <td>0.495970</td>\n",
       "      <td>0.664442</td>\n",
       "      <td>0.005787</td>\n",
       "      <td>0.005843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018126</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048440</td>\n",
       "      <td>0.499861</td>\n",
       "      <td>0.496999</td>\n",
       "      <td>0.035301</td>\n",
       "      <td>0.499259</td>\n",
       "      <td>0.498334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818233</th>\n",
       "      <td>0.049801</td>\n",
       "      <td>0.047945</td>\n",
       "      <td>0.039999</td>\n",
       "      <td>0.055094</td>\n",
       "      <td>0.046194</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.544106</td>\n",
       "      <td>0.193217</td>\n",
       "      <td>0.002163</td>\n",
       "      <td>0.103662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133231</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.072579</td>\n",
       "      <td>0.632222</td>\n",
       "      <td>0.378103</td>\n",
       "      <td>0.014967</td>\n",
       "      <td>0.587444</td>\n",
       "      <td>0.326544</td>\n",
       "      <td>0.082818</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818234</th>\n",
       "      <td>0.046515</td>\n",
       "      <td>0.031070</td>\n",
       "      <td>0.041983</td>\n",
       "      <td>0.023231</td>\n",
       "      <td>0.379642</td>\n",
       "      <td>0.092256</td>\n",
       "      <td>0.447357</td>\n",
       "      <td>0.376331</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.099593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116347</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.069433</td>\n",
       "      <td>0.643667</td>\n",
       "      <td>0.361871</td>\n",
       "      <td>0.050975</td>\n",
       "      <td>0.275778</td>\n",
       "      <td>0.960376</td>\n",
       "      <td>0.096150</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818235</th>\n",
       "      <td>0.051259</td>\n",
       "      <td>0.010155</td>\n",
       "      <td>0.043797</td>\n",
       "      <td>0.006351</td>\n",
       "      <td>0.275633</td>\n",
       "      <td>0.072274</td>\n",
       "      <td>0.495970</td>\n",
       "      <td>0.457153</td>\n",
       "      <td>0.006351</td>\n",
       "      <td>0.010818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048440</td>\n",
       "      <td>0.499861</td>\n",
       "      <td>0.496999</td>\n",
       "      <td>0.035301</td>\n",
       "      <td>0.499259</td>\n",
       "      <td>0.498334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818236</th>\n",
       "      <td>0.045184</td>\n",
       "      <td>0.020653</td>\n",
       "      <td>0.045132</td>\n",
       "      <td>0.010498</td>\n",
       "      <td>0.275633</td>\n",
       "      <td>0.072274</td>\n",
       "      <td>0.495970</td>\n",
       "      <td>0.409706</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.027335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091375</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.662222</td>\n",
       "      <td>0.919637</td>\n",
       "      <td>0.035301</td>\n",
       "      <td>0.499259</td>\n",
       "      <td>0.498334</td>\n",
       "      <td>0.016591</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818237</th>\n",
       "      <td>0.042948</td>\n",
       "      <td>0.082700</td>\n",
       "      <td>0.053082</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.275633</td>\n",
       "      <td>0.072274</td>\n",
       "      <td>0.495970</td>\n",
       "      <td>0.410969</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.015368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048440</td>\n",
       "      <td>0.499861</td>\n",
       "      <td>0.496999</td>\n",
       "      <td>0.035301</td>\n",
       "      <td>0.499259</td>\n",
       "      <td>0.498334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>818238 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DER_mass_MMC  DER_mass_transverse_met_lep  DER_mass_vis  DER_pt_h  \\\n",
       "0           0.066707                     0.053326      0.068128  0.009869   \n",
       "1           0.078287                     0.070992      0.072155  0.016983   \n",
       "2           0.058150                     0.167417      0.089071  0.012570   \n",
       "3           0.069508                     0.084050      0.055557  0.000146   \n",
       "4           0.085980                     0.017462      0.095662  0.005787   \n",
       "...              ...                          ...           ...       ...   \n",
       "818233      0.049801                     0.047945      0.039999  0.055094   \n",
       "818234      0.046515                     0.031070      0.041983  0.023231   \n",
       "818235      0.051259                     0.010155      0.043797  0.006351   \n",
       "818236      0.045184                     0.020653      0.045132  0.010498   \n",
       "818237      0.042948                     0.082700      0.053082  0.001405   \n",
       "\n",
       "        DER_deltaeta_jet_jet  DER_mass_jet_jet  DER_prodeta_jet_jet  \\\n",
       "0                   0.104310          0.022395             0.591293   \n",
       "1                   0.275633          0.072274             0.495970   \n",
       "2                   0.275633          0.072274             0.495970   \n",
       "3                   0.275633          0.072274             0.495970   \n",
       "4                   0.275633          0.072274             0.495970   \n",
       "...                      ...               ...                  ...   \n",
       "818233              0.046194          0.006882             0.544106   \n",
       "818234              0.379642          0.092256             0.447357   \n",
       "818235              0.275633          0.072274             0.495970   \n",
       "818236              0.275633          0.072274             0.495970   \n",
       "818237              0.275633          0.072274             0.495970   \n",
       "\n",
       "        DER_deltar_tau_lep  DER_pt_tot  DER_sum_pt  ...  PRI_met_sumet  \\\n",
       "0                 0.515244    0.014789    0.074595  ...       0.112586   \n",
       "1                 0.589031    0.000733    0.038884  ...       0.069314   \n",
       "2                 0.530399    0.003293    0.074622  ...       0.113359   \n",
       "3                 0.559625    0.000146    0.014690  ...       0.033256   \n",
       "4                 0.664442    0.005787    0.005843  ...       0.018126   \n",
       "...                    ...         ...         ...  ...            ...   \n",
       "818233            0.193217    0.002163    0.103662  ...       0.133231   \n",
       "818234            0.376331    0.001019    0.099593  ...       0.116347   \n",
       "818235            0.457153    0.006351    0.010818  ...       0.080387   \n",
       "818236            0.409706    0.000966    0.027335  ...       0.091375   \n",
       "818237            0.410969    0.001405    0.015368  ...       0.038455   \n",
       "\n",
       "        PRI_jet_num  PRI_jet_leading_pt  PRI_jet_leading_eta  \\\n",
       "0          0.666667            0.033028             0.738889   \n",
       "1          0.333333            0.014316             0.580556   \n",
       "2          0.333333            0.012573             0.728111   \n",
       "3          0.000000            0.048440             0.499861   \n",
       "4          0.000000            0.048440             0.499861   \n",
       "...             ...                 ...                  ...   \n",
       "818233     0.666667            0.072579             0.632222   \n",
       "818234     0.666667            0.069433             0.643667   \n",
       "818235     0.000000            0.048440             0.499861   \n",
       "818236     0.333333            0.000761             0.662222   \n",
       "818237     0.000000            0.048440             0.499861   \n",
       "\n",
       "        PRI_jet_leading_phi  PRI_jet_subleading_pt  PRI_jet_subleading_eta  \\\n",
       "0                  0.570656               0.020388                0.637778   \n",
       "1                  0.684278               0.035301                0.499259   \n",
       "2                  0.177276               0.035301                0.499259   \n",
       "3                  0.496999               0.035301                0.499259   \n",
       "4                  0.496999               0.035301                0.499259   \n",
       "...                     ...                    ...                     ...   \n",
       "818233             0.378103               0.014967                0.587444   \n",
       "818234             0.361871               0.050975                0.275778   \n",
       "818235             0.496999               0.035301                0.499259   \n",
       "818236             0.919637               0.035301                0.499259   \n",
       "818237             0.496999               0.035301                0.499259   \n",
       "\n",
       "        PRI_jet_subleading_phi  PRI_jet_all_pt  Label  \n",
       "0                     0.106143        0.061014    1.0  \n",
       "1                     0.498334        0.024850    0.0  \n",
       "2                     0.498334        0.023789    0.0  \n",
       "3                     0.498334        0.000000    0.0  \n",
       "4                     0.498334        0.000000    0.0  \n",
       "...                        ...             ...    ...  \n",
       "818233                0.326544        0.082818    1.0  \n",
       "818234                0.960376        0.096150    1.0  \n",
       "818235                0.498334        0.000000    0.0  \n",
       "818236                0.498334        0.016591    0.0  \n",
       "818237                0.498334        0.000000    0.0  \n",
       "\n",
       "[818238 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "data[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data=data, x='Label', hue='Label', dodge=False, legend=False)\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (818238, 31)\n",
      "Reduced shape: (818238, 10)\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components = 0.90)\n",
    "\n",
    "data_reduced = pca.fit_transform(data)\n",
    "\n",
    "print(f\"Original shape: {data.shape}\")\n",
    "print(f\"Reduced shape: {data_reduced.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(572766, 10) (245472, 10) (572766,) (245472,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "x = data_reduced\n",
    "y = data[\"Label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=42)\n",
    "\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 136.95007252693176\n",
      "Random Forest - Accuracy: 1.0, Precision: 1.0, Recall: 1.0, F1-Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, criterion='gini', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', min_impurity_decrease=0.0, verbose=0, ccp_alpha=0.0)\n",
    "\n",
    "deb = time.time()\n",
    "rf_model.fit(X_train, y_train)\n",
    "fin = time.time()\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "time_rf = fin-deb\n",
    "print(\"Time taken:\", time_rf)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Random Forest - Accuracy: {accuracy_rf}, Precision: {precision_rf}, Recall: {recall_rf}, F1-Score: {f1_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\miche\\Documents\\Erasmus\\DeVinci\\Advanced ML II\\venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [23:02:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.7739958763122559\n",
      "XGBoost - Accuracy: 1.0, Precision: 1.0, Recall: 1.0, F1-Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier(eval_metric='mlogloss', use_label_encoder=False)\n",
    "\n",
    "deb = time.time()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "fin = time.time()\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "time_xgb = fin-deb\n",
    "print(\"Time taken:\", time_xgb)\n",
    "\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "precision_xgb = precision_score(y_test, y_pred_xgb)\n",
    "recall_xgb = recall_score(y_test, y_pred_xgb)\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"XGBoost - Accuracy: {accuracy_xgb}, Precision: {precision_xgb}, Recall: {recall_xgb}, F1-Score: {f1_xgb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evolutionary Learning Implementation with DEAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m population \u001b[38;5;241m=\u001b[39m toolbox\u001b[38;5;241m.\u001b[39mpopulation(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)  \u001b[38;5;66;03m# Size of population\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Algorithm parameters\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meaSimple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoolbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcxpb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmutpb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mngen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mstats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhalloffame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\miche\\Documents\\Erasmus\\DeVinci\\Advanced ML II\\venv\\Lib\\site-packages\\deap\\algorithms.py:151\u001b[0m, in \u001b[0;36meaSimple\u001b[1;34m(population, toolbox, cxpb, mutpb, ngen, stats, halloffame, verbose)\u001b[0m\n\u001b[0;32m    149\u001b[0m invalid_ind \u001b[38;5;241m=\u001b[39m [ind \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m population \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ind\u001b[38;5;241m.\u001b[39mfitness\u001b[38;5;241m.\u001b[39mvalid]\n\u001b[0;32m    150\u001b[0m fitnesses \u001b[38;5;241m=\u001b[39m toolbox\u001b[38;5;241m.\u001b[39mmap(toolbox\u001b[38;5;241m.\u001b[39mevaluate, invalid_ind)\n\u001b[1;32m--> 151\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minvalid_ind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfitnesses\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mind\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfitness\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfit\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m halloffame \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[11], line 16\u001b[0m, in \u001b[0;36mevalSymbReg\u001b[1;34m(individual)\u001b[0m\n\u001b[0;32m     14\u001b[0m X_train_sub \u001b[38;5;241m=\u001b[39m X_train[:, individual\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\u001b[38;5;241m.\u001b[39mflatten()]\n\u001b[0;32m     15\u001b[0m X_test_sub \u001b[38;5;241m=\u001b[39m X_test[:, individual\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\u001b[38;5;241m.\u001b[39mflatten()]\n\u001b[1;32m---> 16\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_sub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test_sub)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (accuracy_score(y_test, y_pred),)\n",
      "File \u001b[1;32mc:\\Users\\miche\\Documents\\Erasmus\\DeVinci\\Advanced ML II\\venv\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\miche\\Documents\\Erasmus\\DeVinci\\Advanced ML II\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    481\u001b[0m ]\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\miche\\Documents\\Erasmus\\DeVinci\\Advanced ML II\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\miche\\Documents\\Erasmus\\DeVinci\\Advanced ML II\\venv\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\miche\\Documents\\Erasmus\\DeVinci\\Advanced ML II\\venv\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\miche\\Documents\\Erasmus\\DeVinci\\Advanced ML II\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\miche\\Documents\\Erasmus\\DeVinci\\Advanced ML II\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 192\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    201\u001b[0m         X,\n\u001b[0;32m    202\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    206\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\miche\\Documents\\Erasmus\\DeVinci\\Advanced ML II\\venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize DEAP structures\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))  # Maximize classification accuracy\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "# Create the primitive set (basic operations)\n",
    "def evalSymbReg(individual):\n",
    "    # Basic GP function: Evaluate the individual in a classifier task (acc or f1)\n",
    "    model = RandomForestClassifier()\n",
    "    individual = np.array(individual).reshape(-1, 1)\n",
    "    X_train_sub = X_train[:, individual.astype(int).flatten()]\n",
    "    X_test_sub = X_test[:, individual.astype(int).flatten()]\n",
    "    model.fit(X_train_sub, y_train)\n",
    "    y_pred = model.predict(X_test_sub)\n",
    "    return (accuracy_score(y_test, y_pred),)\n",
    "\n",
    "# Evolutionary algorithm functions\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_int\", random.randint, 0, X.shape[1] - 1)  # randomly select feature\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_int, n=10)  # number of features\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "# Selection, crossover, mutation\n",
    "toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "toolbox.register(\"mutate\", tools.mutShuffleIndexes, indpb=0.2)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "toolbox.register(\"evaluate\", evalSymbReg)\n",
    "\n",
    "# Create population\n",
    "population = toolbox.population(n=50)  # Size of population\n",
    "\n",
    "# Algorithm parameters\n",
    "algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=5, \n",
    "                    stats=None, halloffame=None, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 19\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m metrics\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Compare performances\u001b[39;00m\n\u001b[0;32m     18\u001b[0m results \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mevaluate_performance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrf_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXGBoost\u001b[39m\u001b[38;5;124m\"\u001b[39m: evaluate_performance(xgb_model, X_train, X_test, y_train, y_test),\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# Add evolutionary learning model results here\u001b[39;00m\n\u001b[0;32m     22\u001b[0m }\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Output results\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, metrics \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[1;32mIn[17], line 4\u001b[0m, in \u001b[0;36mevaluate_performance\u001b[1;34m(model, X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_performance\u001b[39m(model, X_train, X_test, y_train, y_test):\n\u001b[0;32m      3\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      6\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\Users\\miche\\Documents\\Erasmus\\DeVinci\\Advanced ML II\\venv\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\miche\\Documents\\Erasmus\\DeVinci\\Advanced ML II\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    481\u001b[0m ]\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\miche\\Documents\\Erasmus\\DeVinci\\Advanced ML II\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\miche\\Documents\\Erasmus\\DeVinci\\Advanced ML II\\venv\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\miche\\Documents\\Erasmus\\DeVinci\\Advanced ML II\\venv\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\miche\\Documents\\Erasmus\\DeVinci\\Advanced ML II\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\miche\\Documents\\Erasmus\\DeVinci\\Advanced ML II\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 192\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    201\u001b[0m         X,\n\u001b[0;32m    202\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    206\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\miche\\Documents\\Erasmus\\DeVinci\\Advanced ML II\\venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Performance evaluation function for all models\n",
    "def evaluate_performance(model, X_train, X_test, y_train, y_test):\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    metrics = {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"F1-Score\": f1_score(y_test, y_pred),\n",
    "        \"Training Time\": end_time - start_time\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# Compare performances\n",
    "results = {\n",
    "    \"Random Forest\": evaluate_performance(rf_model, X_train, X_test, y_train, y_test),\n",
    "    \"XGBoost\": evaluate_performance(xgb_model, X_train, X_test, y_train, y_test),\n",
    "    # Add evolutionary learning model results here\n",
    "}\n",
    "\n",
    "# Output results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"{model_name} Performance:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparative analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x600 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = {\n",
    "    \"Random Forest\": {\"Accuracy\": accuracy_rf, \"Precision\": precision_rf, \"Recall\": recall_rf, \"F1\": f1_rf, \"Time\": time_rf},\n",
    "    \"XGBoost\": {\"Accuracy\": accuracy_xgb, \"Precision\": precision_xgb, \"Recall\": recall_xgb, \"F1\": f1_xgb, \"Time\": time_xgb},\n",
    "    # Add evolutionary learning model results here\n",
    "}\n",
    "\n",
    "models = list(results.keys())\n",
    "metrics = [\"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"Time\"]\n",
    "\n",
    "# Prepare the figure and axes\n",
    "fig, axes = plt.subplots(1, len(metrics), figsize=(20, 6))\n",
    "\n",
    "# For each metric, plot the values across models\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax = axes[i]\n",
    "    ax.bar(models, [results[model][metric] for model in models])\n",
    "    ax.set_title(f'{metric} Comparison')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_ylim(0, 1) if metric != 'Time' else ax.set_ylim(0, max(results[model][\"Time\"] for model in models) + 10)\n",
    "\n",
    "# Adjust layout to prevent overlapping of labels\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
